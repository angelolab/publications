{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebc3fe0e-5c93-4822-9622-0c6caf63ae66",
   "metadata": {},
   "source": [
    "# LDA post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4d77b0-930c-4ee8-9a95-2f4948aab19e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io as io\n",
    "from skimage.segmentation import find_boundaries\n",
    "import spatial_lda.model\n",
    "import spatial_lda.visualization\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "import ark.utils.spatial_lda_utils as spu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98e5e7c-2faa-4c63-b824-69dc03a32924",
   "metadata": {},
   "source": [
    "## Make LDA cell table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b2fd2-67c7-4aa3-9e49-471c8b8f0c3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = \"../data\"\n",
    "processed_dir = \"spatial_analysis/spatial_lda/preprocessed\"\n",
    "complete_name = \"complete_spatial_lda_model_num_topics=6_diff=250\"\n",
    "cell_table_name = \"formatted_cell_table\"\n",
    "seg_cell_tab_path = os.path.join(base_dir, \"tables\", \"cell_table_size_normalized.csv\")\n",
    "save_path = os.path.join(base_dir, \"tables\", \"cell_table_spatial_lda.csv\")\n",
    "\n",
    "processed_path = os.path.join(base_dir, processed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed8831-b7dc-405c-bb62-4ecd448c9647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get data\n",
    "complete_model = spu.read_spatial_lda_file(dir=processed_path, file_name=complete_name, format=\"pkl\")\n",
    "cell_table = spu.read_spatial_lda_file(dir=processed_path, file_name=cell_table_name, format=\"pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9875b7-39bd-4cf0-8ed2-ffde92b4e65d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Look at some examples to make sure model loaded propperly\n",
    "fov_set = ['sample1_fov1','sample10_fov10']\n",
    "_plot_fn = spu.make_plot_fn(\n",
    "    plot=\"topic_assignment\", topic_weights=complete_model.topic_weights, cell_table=cell_table)\n",
    "spatial_lda.visualization.plot_samples_in_a_row(\n",
    "    complete_model.topic_weights, _plot_fn, cell_table, fov_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b315ec-4e63-4f8e-a45c-4a72b9269b81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make one large cell table from spatial LDA object\n",
    "dfs_list = []\n",
    "\n",
    "for key, df in cell_table.items():\n",
    "    if 'sample' in key:\n",
    "        temp_df = pd.DataFrame(df)\n",
    "        temp_df['fov'] = key\n",
    "        temp_df = temp_df.reset_index(names=\"index\")\n",
    "        dfs_list.append(temp_df[['fov','index','x','y','cluster']])\n",
    "\n",
    "combined_cell_tab = pd.concat(dfs_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8989668-4363-4d2c-a874-e2ae8a966fbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get LDA weights\n",
    "lda_tab = complete_model.topic_weights\n",
    "lda_tab['fov'] = [index[0] for index in lda_tab.index]\n",
    "lda_tab['index'] = [index[1] for index in lda_tab.index]\n",
    "lda_tab = lda_tab.reset_index(drop=True)\n",
    "\n",
    "combined_cell_tab = pd.merge(combined_cell_tab, lda_tab, on=['fov','index'])\n",
    "combined_cell_tab = combined_cell_tab.rename(columns={'x':'centroid-0',\n",
    "                                                      'y':'centroid-1',\n",
    "                                                      'cluster':'cell_meta_cluster'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed700e18-1d63-484a-aadb-4d458220eebe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get segmentation labels\n",
    "seg_cell_table = pd.read_csv(seg_cell_tab_path)\n",
    "combined_cell_tab = pd.merge(seg_cell_table[['fov','label','centroid-0','centroid-1','cell_meta_cluster']], combined_cell_tab, on=['fov','centroid-0','centroid-1','cell_meta_cluster'])\n",
    "combined_cell_tab = combined_cell_tab.drop('index', axis=1)\n",
    "\n",
    "# Get highest probability topic\n",
    "topic_cols = [x for x in combined_cell_tab if 'Topic' in x]\n",
    "combined_cell_tab['lda_me'] = combined_cell_tab[topic_cols].idxmax(axis=1)\n",
    "\n",
    "combined_cell_tab.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f5e7e-1046-454d-a6d3-622a2a94ed8b",
   "metadata": {},
   "source": [
    "## Make LDA masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13f42d9-c461-4f6d-b205-9a2245839e94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lda_tab_path = os.path.join(\"../data\", \"tables\", \"cell_table_spatial_lda.csv\")\n",
    "seg_dir = \"../data/segmentation_masks\"\n",
    "\n",
    "combined_cell_tab = pd.read_csv(lda_tab_path)\n",
    "all_fovs = np.unique(combined_cell_tab['fov'])\n",
    "all_topics = [x for x in combined_cell_tab.columns.values if 'Topic' in x]\n",
    "\n",
    "# Extract topic with maximum score\n",
    "combined_cell_tab['lda_me_int'] = combined_cell_tab['lda_me'].str.extract('(\\d+)').astype(int) + 1\n",
    "combined_cell_tab['lda_me_score'] = [\n",
    "    combined_cell_tab.loc[idx, f'Topic-{me-1}'] \n",
    "    for idx, me in zip(combined_cell_tab.index, combined_cell_tab['lda_me_int'])\n",
    "]\n",
    "\n",
    "output_dir_individual = \"../data/colored_lda_masks_individual\"\n",
    "output_dir_composite = \"../data/colored_lda_masks_scores\"\n",
    "output_dir_composite_int = \"../data/colored_lda_masks\"\n",
    "if not os.path.exists(output_dir_individual):\n",
    "    os.makedirs(output_dir_individual)\n",
    "if not os.path.exists(output_dir_composite):\n",
    "    os.makedirs(output_dir_composite)\n",
    "if not os.path.exists(output_dir_composite_int):\n",
    "    os.makedirs(output_dir_composite_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17196df1-a050-4646-afa0-f79f16d42ba9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Colors\n",
    "maxnum = 100\n",
    "bounds_individual = [i-0.5 for i in np.linspace(0, maxnum+1, maxnum+2)]\n",
    "\n",
    "num_topics = len(all_topics)\n",
    "bounds_composite_int = [i-0.5 for i in np.linspace(0,num_topics+1,num_topics+2)]\n",
    "\n",
    "white = np.array([1, 1, 1, 1])  # RGBA for white\n",
    "topic_colors = [[0.243, 0.349, 0.224, 1],\n",
    "                [0.639, 0.784, 0.745, 1],\n",
    "                [0.596, 0.420, 0.502, 1],\n",
    "                [0.678, 0.804, 0.906, 1],\n",
    "                [0.482, 0.537, 0.643, 1],\n",
    "                [0.6, 0.573, 0.475, 1]]\n",
    "\n",
    "topic_colors_with_black = [[0, 0, 0, 0]] + topic_colors\n",
    "colmap_composite_int = colors.ListedColormap(topic_colors_with_black)\n",
    "norm_composite_int = colors.BoundaryNorm(bounds_composite_int, colmap_composite_int.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51baa0-da9b-4d55-95cf-4a2ae0a89e84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fov in all_fovs:\n",
    "\n",
    "    print(fov)\n",
    "    seg_array = io.imread(os.path.join(seg_dir, fov+\".tiff\"))\n",
    "    predicted_contour_mask = find_boundaries(seg_array, connectivity=1, mode='inner').astype(np.uint8)\n",
    "    \n",
    "    one_fov_cell_table = combined_cell_tab.loc[combined_cell_tab['fov'] == fov]\n",
    "    \n",
    "    ## One image for each topic\n",
    "    for i,topic in enumerate(all_topics):\n",
    "        fov_cell_dict = dict(zip(one_fov_cell_table['label'], one_fov_cell_table[topic]))\n",
    "        fov_cell_dict[0] = 0\n",
    "        \n",
    "        dark_col = topic_colors[i]\n",
    "        mycols = [white + (dark_col - white) * (i / (maxnum+1)) for i in range(maxnum+2)]\n",
    "        colmap = colors.ListedColormap(mycols)\n",
    "        norm = colors.BoundaryNorm(bounds_individual, colmap.N)\n",
    "\n",
    "        lda_array = np.vectorize(fov_cell_dict.get, otypes=[float])(seg_array)\n",
    "        lda_array = lda_array*100\n",
    "\n",
    "        image = colmap(norm(lda_array))\n",
    "        # Add cell borders\n",
    "        image[predicted_contour_mask > 0] = [0, 0, 0, 1]\n",
    "        # Change empty slide to black\n",
    "        image[seg_array == 0] = [0, 0, 0, 1]\n",
    "\n",
    "        plt.imsave(os.path.join(output_dir_individual, fov+\"_\"+topic+\".tiff\"), image)\n",
    "    \n",
    "    \n",
    "    ## One with image with gradient for ME score\n",
    "    fov_cell_dict = dict(zip(one_fov_cell_table['label'], one_fov_cell_table['lda_me_int']))\n",
    "    fov_cell_dict_score = dict(zip(one_fov_cell_table['label'], one_fov_cell_table['lda_me_score']))\n",
    "    \n",
    "    fov_cell_dict[0] = 0\n",
    "    fov_cell_dict_score[0] = 0\n",
    "    \n",
    "    me_array = np.vectorize(fov_cell_dict.get)(seg_array)\n",
    "    score_array = np.vectorize(fov_cell_dict_score.get, otypes=[float])(seg_array)\n",
    "    \n",
    "    image = np.zeros((seg_array.shape[0], seg_array.shape[1], 4))\n",
    "    for i in range(len(topic_colors)):\n",
    "        mask = (me_array == i+1)\n",
    "        if np.any(mask):\n",
    "            # Get the values in this region (0 to 1)\n",
    "            values = score_array[mask]\n",
    "            # Create colors that blend from white to the ME color based on value\n",
    "            color_array = np.zeros((np.sum(mask), 4))\n",
    "            for j in range(3):  # RGB channels\n",
    "                color_array[:, j] = white[j] + (topic_colors[i][j] - white[j]) * values\n",
    "            # Set alpha channel\n",
    "            color_array[:, 3] = 1.0\n",
    "            # Assign these colors to the image\n",
    "            image[mask] = color_array\n",
    "\n",
    "    # Add cell borders\n",
    "    image[predicted_contour_mask > 0] = [0, 0, 0, 1]\n",
    "    # Change empty slide to black\n",
    "    image[seg_array == 0] = [0, 0, 0, 1]\n",
    "    # Save\n",
    "    plt.imsave(os.path.join(output_dir_composite, fov+\".tiff\"), image)\n",
    "    \n",
    "    \n",
    "    ## One with image with assigned ME for each cell\n",
    "    me_array[predicted_contour_mask > 0] = 0\n",
    "    image = colmap_composite_int(norm_composite_int(me_array))\n",
    "    plt.imsave(os.path.join(output_dir_composite_int, fov+\".tiff\"), image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
