{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Liu and Bosse et al., Reproducible, high-dimensional imaging in archival human tissue by Multiplexed Ion Beam Imaging by Time-of-Flight (MIBI-TOF)\n",
    "Code in this notebook normalizes the MIBI-TOF data, performs regression for mean pixel intensity (MPI) and percent pixel positive (PPP), and performs comparison with IHC data.\n",
    "\n",
    "All data necessary to run this notebook are deposited on Zenodo: https://doi.org/10.5281/zenodo.5945388"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess MIBI-TOF data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in MIBI-TOF data table (Ionpath data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ionpath_loc = 'ionpath_processed_data.csv'\n",
    "ionpath_data = pd.read_csv(ionpath_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean raw and filtered intensity. The average values are normalized by the corresponding percent pixel positive value, then scaled up by a factor of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image size is 1024 x 1024, so num pixels is 1024 * 1024\n",
    "num_pixels = 1024 ** 2\n",
    "\n",
    "# calculate the mean intensity values\n",
    "ionpath_data['MeanRawIntensity'] = ionpath_data['RawCounts'] / num_pixels / ionpath_data['PercentPixelPositive'] * 100\n",
    "ionpath_data['MeanFilteredIntensity'] = ionpath_data['FilteredCount'] / num_pixels / ionpath_data['PercentPixelPositive'] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset on the runs desired. The run names are in the following format: `{Y}{M}_Slide{Slide#}Stain{Stain#}Run_{suffix}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define list of runs to use\n",
    "good_runs = ['201001_Slide23Stain2Run_shuffled', '201001_Slide31Stain4Run_restart', '201003_Slide27Stain5Run_shuffled_run',\n",
    "             '201005_Slide29Stain3Run_shuffled_4a', '201005_Slide29Stain3Run_shuffled_4b', '201007_Slide21Stain1Run_shuffled_4a',\n",
    "             '201007_Slide21Stain1Run_shuffled_4b', '201008_Slide25Stain6Run_shuffled_6a', '201008_Slide25Stain6Run_shuffled_6b']\n",
    "\n",
    "# subset on runs specified\n",
    "ionpath_data = ionpath_data[ionpath_data['Run'].isin(good_runs)]\n",
    "\n",
    "# remove any suffixes, such as _shuffled, _restart, ...\n",
    "# combine the results of runs with the same `{Y}{M}_Slide{Slide#}Stain{Stain#}Run` prefixes.\n",
    "ionpath_data['Run'] = ionpath_data.apply(lambda row: '_'.join(row['Run'].split('_')[:2]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset on the FOVs to be included in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define list of FOVs to use\n",
    "good_fovs = ['R1C2', 'R1C3', 'R1C4', 'R1C5', 'R1C7', 'R1C9', 'R1C10',\n",
    "             'R2C10', 'R2C11', 'R2C12', 'R3C2', 'R3C4', 'R6C7', 'R6C10',\n",
    "             'R6C11', 'R7C6', 'R7C7', 'R7C10', 'R8C1', 'R8C10', 'R8C11']\n",
    "\n",
    "# subset on FOVs specified\n",
    "ionpath_data = ionpath_data[ionpath_data['FOVName'].isin(good_fovs)]\n",
    "\n",
    "# there was a problem with one of the points, so remove that point from the analysis\n",
    "ionpath_data = ionpath_data[~((ionpath_data['Point'] == 'Point13') & (ionpath_data['FOVName'] == 'R1C4') & (ionpath_data['Run'] == '201007_Slide21Stain1Run'))]\n",
    "\n",
    "# define a variable to hold all the unique runs (after subsetting)\n",
    "all_runs = ionpath_data['Run'].unique()\n",
    "\n",
    "# define a variable to hold all the unique targets\n",
    "markers = ionpath_data['Target'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get normalization coefficients for MIBI-TOF data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CSV file defining the acquisition order of each run as well as the intensities for each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_intensity_calib_file = 'calibration_data.csv'\n",
    "\n",
    "# this dictionary will help us keep the runs we want and rename the columns so we can easily index into them\n",
    "run_stain_dict = {\n",
    "    'Intensity Run 1': '201001_Slide31Stain4Run',\n",
    "    'Intensity Run 2': '201001_Slide23Stain2Run',\n",
    "    'Intensity Run 3': '201003_Slide27Stain5Run',\n",
    "    'Intensity Run 4': '201005_Slide29Stain3Run',\n",
    "    'Intensity Run 5': '201007_Slide21Stain1Run',\n",
    "    'Intensity Run 6': '201008_Slide25Stain6Run'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function retrieves the calibration coefficients for each FOV across each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calibration_coefs(run_stain_dict, file_name):\n",
    "    norm_coefs = {}\n",
    "    \n",
    "    # read and rename the columns, set index as FOV for ease of use\n",
    "    df = pd.read_csv(file_name)\n",
    "    df = df.rename(run_stain_dict, axis=1)\n",
    "    df = df.set_index('FOV')\n",
    "    \n",
    "    # only extract the columns with Slide in their names (after renaming based on run_stain_dict)\n",
    "    columns = list(df.columns[df.columns.str.contains('Slide')])\n",
    "    df = df.loc[:, columns]\n",
    "    \n",
    "    # compute the average intensity across all values, ignoring NaNs\n",
    "    avg_all_intensities = np.nanmean(df.values)\n",
    "    \n",
    "    # get calibration coefficients for all fovs and stains\n",
    "    for fov in df.index.values:\n",
    "        norm_coefs[fov] = {}\n",
    "        \n",
    "        for stain in run_stain_dict.values():\n",
    "            # extract the specific intensity values for the fov and run\n",
    "            fov_stain_val = df.loc[fov, stain]\n",
    "            \n",
    "            # divide fov intensity by the average\n",
    "            norm_coefs[fov][stain] = fov_stain_val / avg_all_intensities\n",
    "\n",
    "    return pd.DataFrame(norm_coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the calibration coefficients across each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_coefs = get_calibration_coefs(run_stain_dict, acquisition_intensity_calib_file)\n",
    "norm_coefs.to_csv(\"norm_coefs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize MIBI-TOF Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use norm_coefs to calibrate the PercentPixelPositive, MeanRawIntensity, and MeanFilteredIntensity values. Each value is divided by the corresponding calibration coefficient for the particular run/FOV pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_ionpath(agg_runs, markers, ionpath_data, norm_coefs):\n",
    "    ionpath_calib_data = ionpath_data.copy()\n",
    "    columns = ['PercentPixelPositive', 'MeanRawIntensity', 'MeanFilteredIntensity']\n",
    "    \n",
    "    # calibrate PercentPixelPositive, MeanRawIntensity, and FilteredMeanIntensity\n",
    "    # by dividing their respective values by the respective Run and FOV contained in norm_coefs\n",
    "    for col in columns:\n",
    "        ionpath_calib_data['Calibrated%s' % col] = ionpath_calib_data.apply(\n",
    "            lambda row: row[col] / norm_coefs.loc[row['Run'], row['FOVName']], axis=1\n",
    "        )\n",
    "    \n",
    "    return ionpath_calib_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute CalibratedPercentPixelPositive, CalibratedMeanRawIntensity, and CalibratedMeanFilteredIntensity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ionpath_calib_data = calibrate_ionpath(all_runs, markers, ionpath_data, norm_coefs)\n",
    "ionpath_calib_data.to_csv(\"ionpath_norm_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot regression statistics from MIBI-TOF Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to generate the regression slope, goodness of fit (R^2), and p-value for a particular set of x and y values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_reg_results(x_vals, y_vals, intercept=False):\n",
    "    if intercept:\n",
    "        est = sm.OLS(y_vals, sm.add_constant(x_vals)).fit()\n",
    "\n",
    "        # the zeroth index of params and pvalues corresponds to the intercept, so need the first for the slope\n",
    "        m = est.params[1]\n",
    "        r2 = est.rsquared\n",
    "        pval = est.pvalues[1]\n",
    "        resid = est.resid\n",
    "    else:\n",
    "        est = sm.OLS(y_vals, x_vals).fit()\n",
    "\n",
    "        # without an intercept, the only param and pvalue will be for the slope\n",
    "        m = est.params[0]\n",
    "        r2 = est.rsquared\n",
    "        pval = est.pvalues[0]\n",
    "        resid = est.resid\n",
    "    \n",
    "    return m, r2, pval, resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each marker, find the slope and R^2 for each run. Each datapoint is the individual run/FOV data for a channel against the average across all runs for the corresponding FOV and channel.\n",
    "\n",
    "For example, say we're generating the regression data for Run 1, beta-tubulin. For Run 1, beta-tubulin, FOV 1, let's say the value is 1. Let's also say the beta-tubulin, FOV 1 average across all runs is 2. Then the resulting point on the graph will be (2, 1). Points are generated for every FOV, and a regression line is drawn on for the resulting graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ionpath_avg_reg_driver(agg_runs, markers, ionpath_calib_data, to_regress):\n",
    "    # create the DataFrames, for each marker, hold the respective m and r2 result for each run\n",
    "    # for each marker, the regression will be for individual fov data for a run against the average across all runs for the corresponding fov\n",
    "    m_stats = pd.DataFrame(np.nan, index=markers, columns=agg_runs)\n",
    "    r2_stats = pd.DataFrame(np.nan, index=markers, columns=agg_runs)\n",
    "    \n",
    "    # store results to visualize on the heatmap\n",
    "    run_marker_dict = {}\n",
    "    \n",
    "    for run in agg_runs:\n",
    "        # get the individual run data\n",
    "        ionpath_run_data = ionpath_calib_data[ionpath_calib_data['Run'] == run]\n",
    "        \n",
    "        for marker in markers:\n",
    "            if marker not in run_marker_dict:\n",
    "                run_marker_dict[marker] = {}\n",
    "\n",
    "            run_marker_dict[marker][run] = {}\n",
    "            indiv_fov_list = []\n",
    "            avg_fov_list = []\n",
    "            \n",
    "            # get marker data\n",
    "            ionpath_marker_data = ionpath_calib_data[ionpath_calib_data['Target'] == marker]\n",
    "\n",
    "            for fov in ionpath_marker_data['FOVName'].unique():\n",
    "                # make sure we're not trying to get data for a fov that doesn't exist for the current run\n",
    "                if fov not in ionpath_run_data['FOVName'].unique():\n",
    "                    continue\n",
    "\n",
    "                # for each fov, get the average across all runs for a specified marker\n",
    "                ionpath_fov_data = ionpath_marker_data[ionpath_marker_data['FOVName'] == fov]\n",
    "                avg_all_runs = ionpath_fov_data[to_regress].mean()\n",
    "\n",
    "                # now get the specific data for the fov and marker for the run we're on\n",
    "                ionpath_indiv_data = ionpath_run_data[(ionpath_run_data['Target'] == marker) & (ionpath_run_data['FOVName'] == fov)]\n",
    "                assert ionpath_indiv_data.shape[0] == 1\n",
    "                \n",
    "                ionpath_indiv_data = ionpath_indiv_data[to_regress].values[0]\n",
    "                \n",
    "                # append the values to the list: (specific fov/marker value for a run vs avg fov/marker value across all runs)\n",
    "                indiv_fov_list.append(ionpath_indiv_data)\n",
    "                avg_fov_list.append(avg_all_runs)\n",
    "            \n",
    "            # regression\n",
    "            m, r2, pval, resid = gen_reg_results(avg_fov_list, indiv_fov_list)\n",
    "            \n",
    "            # update the m and r^2 stats for each marker-run pair\n",
    "            m_stats.loc[marker, run] = m\n",
    "            r2_stats.loc[marker, run] = r2\n",
    "            \n",
    "            run_marker_dict[marker][run]['indiv'] = indiv_fov_list\n",
    "            run_marker_dict[marker][run]['avg'] = avg_fov_list\n",
    "            \n",
    "    return m_stats, r2_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute regression statistics for CalibratedPercentPixelPositive and CalibratedMeanFilteredIntensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_stats_avg_ppp, r2_stats_avg_ppp = ionpath_avg_reg_driver(all_runs, markers, ionpath_calib_data, 'CalibratedPercentPixelPositive')\n",
    "m_stats_avg_mi, r2_stats_avg_mi = ionpath_avg_reg_driver(all_runs, markers, ionpath_calib_data, 'CalibratedMeanFilteredIntensity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming and reordering for visualization:\n",
    "\n",
    "* `marker_rename`: shorten the names of certain markers\n",
    "* `run_sort`: define a custom sorting order for the runs provided\n",
    "* `run_rename`: rename the runs in the format `Slide{n}_StainDay{StainDay#}_RunDay{RunDay#}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename for better visualization\n",
    "marker_rename = {'HLA class 1 A, B, and C, Na-K-ATPase alpha1': 'HLA1 + ATPase'}\n",
    "\n",
    "run_sort = ['201007_Slide21Stain1Run', '201001_Slide23Stain2Run', '201008_Slide25Stain6Run',\n",
    "            '201003_Slide27Stain5Run', '201005_Slide29Stain3Run', '201001_Slide31Stain4Run']\n",
    "\n",
    "run_rename = {'201007_Slide21Stain1Run': 'Slide1_StainDay1_RunDay4',\n",
    "              '201001_Slide23Stain2Run': 'Slide3_StainDay2_RunDay1',\n",
    "              '201008_Slide25Stain6Run': 'Slide5_StainDay6_RunDay5',\n",
    "              '201003_Slide27Stain5Run': 'Slide7_StainDay5_RunDay2',\n",
    "              '201005_Slide29Stain3Run': 'Slide9_StainDay3_RunDay3',\n",
    "              '201001_Slide31Stain4Run': 'Slide11_StainDay4_RunDay1'}\n",
    "\n",
    "m_stats_avg_ppp_reord = m_stats_avg_ppp.rename(marker_rename, axis=0)[list(run_rename.keys())].rename(run_rename, axis=1)\n",
    "r2_stats_avg_ppp_reord = r2_stats_avg_ppp.rename(marker_rename, axis=0)[list(run_rename.keys())].rename(run_rename, axis=1)\n",
    "\n",
    "m_stats_avg_mi_reord = m_stats_avg_mi.rename(marker_rename, axis=0)[list(run_rename.keys())].rename(run_rename, axis=1)\n",
    "r2_stats_avg_mi_reord = r2_stats_avg_mi.rename(marker_rename, axis=0)[list(run_rename.keys())].rename(run_rename, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to visualize the heatmap of MIBI-TOF data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ionpath_heatmap_viz_avg(ionpath_arr, stat, metric):\n",
    "    # create the binary mask array\n",
    "    arr_bin = ionpath_arr.values.copy()\n",
    "\n",
    "    # define the tick values to use\n",
    "    if metric == 'm':\n",
    "        tick_locs = [0, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2]\n",
    "    elif metric == 'r2':\n",
    "        tick_locs = [0, 0.25, 0.5, 0.75, 1.0]\n",
    "    \n",
    "    tick_labels = [str(loc) for loc in tick_locs]\n",
    "\n",
    "    _ = plt.figure(figsize=(10, 10), edgecolor='black')\n",
    "\n",
    "    # use Seaborn to visualize a heatmap of the results\n",
    "    if metric == 'm':\n",
    "        ax = sns.heatmap(ionpath_arr.values, annot=ionpath_arr.values, fmt='.2f',\n",
    "                         xticklabels=[slide.split('_')[0] for slide in ionpath_arr.columns.values],\n",
    "                         yticklabels=ionpath_arr.index.values, cmap='vlag', center=1, vmin=0, vmax=2,\n",
    "                         square=True, linewidths=0.1, linecolor='black', cbar_kws={'ticks': tick_locs})\n",
    "    elif metric == 'r2':\n",
    "        tick_locs = np.linspace(0.5, 1, 5).tolist()\n",
    "        tick_labels = [str(round(loc, 2)) for loc in tick_locs]\n",
    "        ax = sns.heatmap(ionpath_arr.values, annot=ionpath_arr.values, fmt='.2f',\n",
    "                         xticklabels=[slide.split('_')[0] for slide in ionpath_arr.columns.values],\n",
    "                         yticklabels=ionpath_arr.index.values, cmap='viridis',\n",
    "                         vmin=0.5, vmax=1, square=True, linewidths=0.1, linecolor='black', cbar_kws={'ticks': tick_locs})\n",
    "    \n",
    "    # make the spine visible\n",
    "    for _, spine in ax.spines.items():\n",
    "        _ = spine.set_visible(True)\n",
    "    \n",
    "    # set the colorbar params based on the above\n",
    "    colorbar = ax.collections[0].colorbar\n",
    "    _ = colorbar.set_ticklabels(tick_labels)\n",
    "\n",
    "    # set title\n",
    "    if stat == 'CalibratedPercentPixelPositive':\n",
    "        stat_title = 'Percent Positive Pixels'\n",
    "    elif stat == 'CalibratedMeanFilteredIntensity' or stat == 'CalibratedMeanFilteredIntensityPPPNorm':\n",
    "        stat_title = 'Mean Pixel Intensity'\n",
    "        \n",
    "    if metric == 'm':\n",
    "        metric_title = 'Slope of linear fit'\n",
    "    elif metric == 'r2':\n",
    "        metric_title = 'R\\u00b2'.format(2)\n",
    "\n",
    "    _ = plt.title(\"%s: %s\" % (metric_title, stat_title), fontweight='bold')\n",
    "    \n",
    "    # set the tick parameters\n",
    "    _ = plt.tick_params(axis='both',\n",
    "                        which='both',\n",
    "                        bottom=False,\n",
    "                        top=False,\n",
    "                        left=False,\n",
    "                        right=False)\n",
    "\n",
    "    # set the axis labels\n",
    "    _ = plt.xlabel('Serial section order', fontweight='bold', labelpad=20)\n",
    "    _ = plt.ylabel('Antibody', fontweight='bold', labelpad=20)\n",
    "    \n",
    "    # make x-axis ticks vertical\n",
    "    _ = plt.setp(ax.get_xticklabels(), rotation='vertical')\n",
    "\n",
    "    # save figure\n",
    "    _ = ax.figure.savefig(os.path.join('ionpath_%s_%s_scores' % (stat, metric)), dpi=500, bbox_inches='tight')\n",
    "\n",
    "    # clear figure for next visualization\n",
    "    _ = plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate heatmaps for the slope and R^2 values of CalibratedPercentPixelPositive and CalibratedMeanFilteredIntensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ionpath_heatmap_viz_avg(m_stats_avg_ppp_reord, 'CalibratedPercentPixelPositive', 'm')\n",
    "_ = ionpath_heatmap_viz_avg(r2_stats_avg_ppp_reord, 'CalibratedPercentPixelPositive', 'r2')\n",
    "_ = ionpath_heatmap_viz_avg(m_stats_avg_mi_reord, 'CalibratedMeanFilteredIntensity', 'm')\n",
    "_ = ionpath_heatmap_viz_avg(r2_stats_avg_mi_reord, 'CalibratedMeanFilteredIntensity', 'r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare IHC and MIBI-TOF Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the IHC data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihc_loc = 'ihc_data.csv'\n",
    "ihc_data = pd.read_csv(ihc_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 3 mappings:\n",
    "\n",
    "* `slide_extract`: map the run name to the Ionpath slide extract name (not necessarily the same as found in the run name)\n",
    "* `ihc_slides`: map the marker to each the corresponding IHC slide\n",
    "* `marker_to_slide`: map the marker for each IHC to the corresponding Ionpath run(s). Note that a marker's IHC slide number will determine which Ionpath slide extract numbers to map to. For example, if an IHC slide number is 2, then it should map to Ionpath slide extract 1 and 3 (since 2 is 1 away from both 1 and 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_extract = {\n",
    "    '201007_Slide21Stain1Run': 'Slide1',\n",
    "    '201001_Slide31Stain4Run': 'Slide11',\n",
    "    '201005_Slide29Stain3Run': 'Slide9',\n",
    "    '201001_Slide23Stain2Run': 'Slide3',\n",
    "    '201008_Slide25Stain6Run': 'Slide5',\n",
    "    '201003_Slide27Stain5Run': 'Slide7'\n",
    "}\n",
    "\n",
    "ihc_slides = {\n",
    "    'CD8': 'Slide2',\n",
    "    'PanCK': 'Slide4',\n",
    "    'PAX5': 'Slide8',\n",
    "    'CD68': 'Slide10',\n",
    "    'CD3': 'Slide12'\n",
    "}\n",
    "\n",
    "marker_to_slide = {\n",
    "    'CD8': ['201007_Slide21Stain1Run', '201001_Slide23Stain2Run'],\n",
    "    'CD68': ['201001_Slide31Stain4Run', '201005_Slide29Stain3Run'],\n",
    "    'CD3': ['201001_Slide31Stain4Run'],\n",
    "    'PAX5': ['201005_Slide29Stain3Run'],\n",
    "    'PanCK': ['201001_Slide23Stain2Run', '201008_Slide25Stain6Run']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map each IHC marker to the corresponding Ionpath run name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mapping convenience\n",
    "ihc_data['Run'] = ihc_data['Target']\n",
    "\n",
    "for key in marker_to_slide:\n",
    "    ihc_data['Run'] = np.where(ihc_data['Run'] == key, str(marker_to_slide[key]), ihc_data['Run'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset IHC data on the list of FOVs provided (same as `good_fovs` specified above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihc_data = ihc_data[ihc_data['FOVName'].isin(good_fovs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in mapping of FOV to tissue type (needed for plotting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_data_loc = 'tissue_data.csv'\n",
    "tissue_data = pd.read_csv(tissue_data_loc)\n",
    "tissue_data = tissue_data.set_index('Core')\n",
    "\n",
    "# Define colors for plotting (points in regression plot are colored by tissue type).\n",
    "colors = [\"#E41A1C\",\"#377EB8\",\"#4DAF4A\",\"#984EA3\",\"#FF7F00\",\"#FFFF33\",\"#A65628\",\"#F781BF\",\"#999999\",\"#66C2A5\",\"#FC8D62\",\"#8DA0CB\",\"#E78AC3\",\"#A6D854\",\"#FFD92F\",\"#E5C494\",\"#B3B3B3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to plot the regression results of the IHC data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reg_results_ihc(marker, run_x, run_y, ihc_slide, mibi_slide, all_dat, to_regress_ihc, to_regress_ionpath, save_dir, r2, m=None, intercept=False):\n",
    "    # if the save directory doesn't already exists, make it!\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    \n",
    "    fig = plt.figure(figsize=(50, 50))\n",
    "    \n",
    "    x_vals = all_dat[to_regress_ihc].values\n",
    "    y_vals = all_dat[to_regress_ionpath].values\n",
    "    inds = list(all_dat.index)\n",
    "    \n",
    "    # get an acceptable range for the graph\n",
    "    x_pos = min(x_vals)\n",
    "    y_pos = max(y_vals)\n",
    "\n",
    "    # plot the data\n",
    "    sns.lmplot(x=to_regress_ihc, y=to_regress_ionpath, hue='Tissue', data=all_dat, fit_reg = False, palette=sns.color_palette(colors,len(np.unique(all_dat['Tissue']))))\n",
    "    ax = sns.regplot(x=to_regress_ihc, y=to_regress_ionpath, data=all_dat, scatter_kws={\"zorder\":-1})\n",
    "    \n",
    "    # define the upper and lower bound for both x- and y-axes\n",
    "    _ = ax.set_xbound(lower=0, upper=max(x_vals) + 1)\n",
    "    _ = ax.set_ybound(lower=0, upper=max(y_vals) + 1)\n",
    "    \n",
    "    # set labels\n",
    "    _ = plt.xlabel(run_x, fontsize=18, fontweight='bold', labelpad=20)\n",
    "    _ = plt.ylabel(run_y, fontsize=18, fontweight='bold', labelpad=20)\n",
    "    \n",
    "    # write the actual values on the graph\n",
    "    _ = plt.text(0.05, 0.9, marker, fontsize=28, fontweight='bold', transform=ax.transAxes)\n",
    "    _ = plt.text(0.05, 0.85, \"R^2: %.2f\" % r2, fontsize=18, transform=ax.transAxes)\n",
    "    _ = plt.text(0.05, 0.7, \"MIBI: %s\\nIHC: %s\" % (mibi_slide, ihc_slide), fontsize=18, transform=ax.transAxes)\n",
    "    _ = plt.setp(ax.get_xticklabels(), rotation='vertical', fontsize=18)\n",
    "    _ = plt.setp(ax.get_yticklabels(), fontsize=18)\n",
    "\n",
    "    # save figure\n",
    "    _ = plt.savefig(os.path.join(save_dir, 'marker_%s_%s_%s_vs_%s_%s.png' % (marker, run_y, mibi_slide, run_x, ihc_slide)), dpi=500, bbox_inches='tight')\n",
    "\n",
    "    # now clear the plot\n",
    "    _ = plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the regression results for IHC data. The regression is computed on the IHC metric for a marker compared to the corresponding calibrated MIBI-TOF metric for the marker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ihc_gen_results(marker, run, ihc_data, ionpath_calib_data, to_regress_ihc, to_regress_ionpath, slide_extract, ihc_slides, save_dir):\n",
    "    # subset the data, and set the index to RC/FOVName to make life easy later (the upper is to fix PanCK)\n",
    "    ihc_sub = ihc_data[ihc_data['Target'] == marker]\n",
    "    ionpath_sub = ionpath_calib_data[(ionpath_calib_data['Run'] == run) & (ionpath_calib_data['Target'] == marker.upper())]\n",
    "    ihc_sub = ihc_sub.set_index('FOVName')\n",
    "    ionpath_sub = ionpath_sub.set_index('FOVName')\n",
    "    \n",
    "    # select only the fovs that belong to both ihc and ionpath\n",
    "    ihc_fovs = set(ihc_sub.index.values.tolist())\n",
    "    ionpath_fovs = set(ionpath_sub.index.values.tolist())\n",
    "\n",
    "    fovs_to_select = list(ihc_fovs.intersection(ionpath_fovs))\n",
    "    \n",
    "    # now run the additional subset with only the fovs that belong to both\n",
    "    ihc_sub = ihc_sub.loc[fovs_to_select]\n",
    "    ionpath_sub = ionpath_sub.loc[fovs_to_select]\n",
    "    tissue_sub = tissue_data.loc[fovs_to_select]\n",
    "    \n",
    "    # make one data table with all data\n",
    "    concat_dat = pd.concat([ihc_sub[to_regress_ihc],ionpath_sub[to_regress_ionpath],tissue_sub],axis=1)\n",
    "\n",
    "    # generate the regression results\n",
    "    # we will be including an intercept term in this regression this time around\n",
    "    m, r2, pval, resid = gen_reg_results(concat_dat[to_regress_ihc].values, concat_dat[to_regress_ionpath].values, intercept=True)\n",
    "    \n",
    "    # add residuals to data\n",
    "    concat_dat['residuals'] = resid\n",
    "\n",
    "    # sort data by tissue so that the colors appear in the same order\n",
    "    sorter = [\"Thymus\",\"Lymph node\",\"Colon adenocarcinoma\",\"Spleen\",\"Leiomyosarcoma\",\"Squamous cell carcinoma\",\"Placenta\",\"Tonsil\",\"Foreign body giant cells\",\"Dermal sarcoma\",\"Bladder carcinoma\",\"Salivary cystadenoma\",\"Myxofibrosarcoma\",\"Breast ductal carcinoma\"]\n",
    "    concat_dat.Tissue = concat_dat.Tissue.astype(\"category\")\n",
    "    concat_dat.Tissue.cat.set_categories(sorter, inplace=True)\n",
    "    concat_dat.sort_values([\"Tissue\"], inplace=True)\n",
    "\n",
    "    # Plot regression\n",
    "    _ = plot_reg_results_ihc(marker, 'IHC', 'MIBI', ihc_slides[marker], slide_extract[run], concat_dat,\n",
    "                             to_regress_ihc, to_regress_ionpath,\n",
    "                             save_dir, r2, m, intercept=True)\n",
    "        \n",
    "    return concat_dat[to_regress_ihc].values, concat_dat['residuals'].values, '%s_MIBI_%s_IHC_%s' % (marker, slide_extract[run], ihc_slides[marker])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The driver function for the IHC regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ihc_reg_driver(ihc_data, ionpath_calib_data, to_regress_ihc, to_regress_ionpath, slide_extract, ihc_slides, save_dir):\n",
    "    \n",
    "    all_resid = pd.DataFrame()\n",
    "\n",
    "    # iterate over each marker and run pairing in ihc_data\n",
    "    for marker, run_list in ihc_data[['Target', 'Run']].drop_duplicates().values:\n",
    "        for run in ast.literal_eval(run_list):\n",
    "            ihc, resid, name = ihc_gen_results(marker, run, ihc_data, ionpath_calib_data, to_regress_ihc, to_regress_ionpath, slide_extract, ihc_slides, save_dir)\n",
    "            df = pd.DataFrame(data=resid, columns=['residual'])\n",
    "            df['ihc'] = ihc\n",
    "            df['marker'] = marker\n",
    "            df['run'] = run\n",
    "            df['name'] = name\n",
    "            all_resid = all_resid.append(df, ignore_index=True)\n",
    "    \n",
    "    return all_resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each IHC marker, plot and save the regression results for percent pixel positive against the corresponding calibrated MIBI-TOF data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_resid = ihc_reg_driver(ihc_data, ionpath_calib_data, 'DABPercentPixelPositive', 'CalibratedPercentPixelPositive', slide_extract, ihc_slides, 'regression_plots_ihc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep comparisons we care about\n",
    "keep_resid = all_resid.loc[all_resid['name'].isin(['CD3_MIBI_Slide11_IHC_Slide12','CD8_MIBI_Slide3_IHC_Slide2','CD68_MIBI_Slide9_IHC_Slide10','PanCK_MIBI_Slide5_IHC_Slide4','PAX5_MIBI_Slide9_IHC_Slide8'])]\n",
    "\n",
    "# Divide residual by IHC\n",
    "keep_resid['resid_norm'] = keep_resid['residual']/keep_resid['ihc']\n",
    "keep_resid.to_csv(\"residuals.csv\")\n",
    "\n",
    "# Make plot\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "splot = sns.scatterplot(x='ihc', y='residual', data=keep_resid, hue='marker', palette=sns.color_palette(\"Dark2\",len(np.unique(all_resid['marker']))))\n",
    "splot.set(xlim=(0,100),ylim=(-50,50))\n",
    "splot.legend(title=\"Marker\")\n",
    "plt.xlabel('IHC', fontsize=18, labelpad=20)\n",
    "plt.ylabel('Residual', fontsize=18, labelpad=20)\n",
    "plt.savefig(os.path.join('regression_plots_ihc', 'all_residuals.png'), dpi=500, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
