{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial LDA Training and Inference\n",
    "\n",
    "## Overview and Setup\n",
    "This notebook allows users to train a spatial-LDA topic model using their preprocessed cell data.  The main topics covered are:\n",
    "\n",
    "- [Loading Preprocessed Cell Data](#Loading-Preprocessed-Cell-Data)\n",
    "- [Training and Inspecting the Model](#Training-and-Inspecting-the-Model)\n",
    "- [Inferring Topic Weights on New Data](#Inferring-Topic-Weights-on-New-Data)\n",
    "- [Visualizing and Saving Results](#Visualizing-and-Saving-Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import spatial_lda.model\n",
    "import spatial_lda.visualization\n",
    "\n",
    "import ark.utils.spatial_lda_utils as spu\n",
    "from ark.utils import example_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading Preprocessed Cell Data\n",
    "\n",
    "In order to train a spatial-LDA model, the cell table must have been formatted and featurized using the steps in the `LDA_Preprocessing` notebook.  In addition, the required difference matrices should also have been generated through the use of the preprocessing notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Example Dataset\n",
    "\n",
    "Here we are using the example data located in `/data/example_dataset/input_data`. To modify this notebook to run using your own data, simply change the `base_dir` to point to your own sub-directory within the data folder, rather than `'example_dataset'`.\n",
    "\n",
    "* `base_dir`: the path to all of your imaging data. This directory will contain all of the data generated by this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up File Paths\n",
    "- `base_dir`: working directory\n",
    "- `processed_dir`: directory containing the processed data produced from the `LDA_Preprocessing` notebook\n",
    "- `cell_table_name`: name of the correctly formatted cell table file (`.pkl`)\n",
    "- `difference_matrices_name`: name of the difference matrices file (`.pkl`)\n",
    "- `features_name`: name of the featurized cell table file (`.pkl`)\n",
    "- `viz_dir`: destination directory for all plots and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_dir = \"spatial_analysis/spatial_lda/preprocessed\"\n",
    "cell_table_name = \"formatted_cell_table\"\n",
    "difference_matrices_name = \"difference_mats\"\n",
    "features_name = \"featurized_cell_table\"\n",
    "viz_dir = os.path.join(base_dir, \"spatial_analysis/spatial_lda/visualization\")\n",
    "\n",
    "processed_path = os.path.join(base_dir, processed_dir)\n",
    "\n",
    "# Create directories if they do not exist\n",
    "if not os.path.exists(viz_dir):\n",
    "    os.makedirs(viz_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_table = spu.read_spatial_lda_file(\n",
    "    dir=processed_path, file_name=cell_table_name, format=\"pkl\")\n",
    "\n",
    "difference_matrices = spu.read_spatial_lda_file(\n",
    "    dir=processed_path, file_name=difference_matrices_name, format=\"pkl\")\n",
    "\n",
    "featurized_cell_table = spu.read_spatial_lda_file(\n",
    "    dir=processed_path, file_name=features_name, format=\"pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training and Inspecting the Model\n",
    "\n",
    "Model training takes place using a subset of the cell data to speed up the process.  To further save time, one can leverage parallel processing, if possible, by specifying the number of local CPUs to use.  For example, a new MacBook Pro or MacBook Air comes standard with 8 CPUs.  If using parallel processing, you should set the number of processes to be a divisor of the number of FOVs.\n",
    "\n",
    "*Note: if using all available cores for model training, you should not have any other processes running at the same time.*\n",
    "\n",
    "#### Setting Training Parameters\n",
    "You can specify the number of parallel processes, topics, and the difference penalty below.  Larger values for the difference penalty mean adjacent cells are more likely to share topic preferences.\n",
    "\n",
    "To see periodic progress updates, set `verbose=1`.  For more detailed output, set `verbose=2`.  Set `verbose=0` to silence all progress output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if you've already trained the model, set this to True to skip training\n",
    "load_trained_model = True\n",
    "\n",
    "num_processes = 4\n",
    "num_topics = 6\n",
    "difference_penalty = 250\n",
    "verbose = 2\n",
    "\n",
    "#logger = logging.getLogger()\n",
    "#logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Run Training Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not load_trained_model:\n",
    "    trained_model = spatial_lda.model.train(\n",
    "        sample_features=featurized_cell_table[\"train_features\"],\n",
    "        difference_matrices=difference_matrices[\"train_diff_mat\"],\n",
    "        n_parallel_processes=num_processes,\n",
    "        n_topics=num_topics,\n",
    "        difference_penalty=difference_penalty,\n",
    "        verbosity=verbose\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not load_trained_model:\n",
    "    # Trained Model\n",
    "    train_name = \"trained_spatial_lda_model_num_topics={}_diff={}\".format(\n",
    "        num_topics, difference_penalty)\n",
    "\n",
    "    spu.save_spatial_lda_file(\n",
    "        data=trained_model,\n",
    "        dir=os.path.join(base_dir, processed_dir),\n",
    "        file_name=train_name,\n",
    "        format=\"pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if load_trained_model:\n",
    "    # Trained Model\n",
    "    train_name = \"trained_spatial_lda_model_num_topics={}_diff={}\".format(\n",
    "        num_topics, difference_penalty)\n",
    "    trained_model = spu.read_spatial_lda_file(\n",
    "        dir=processed_path, file_name=train_name, format=\"pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Visualize Topic Heatmap\n",
    "The code below produces a heatmap of cell features against topic loadings and saves the output as a `png` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "heatmap_path = os.path.join(\n",
    "    viz_dir, \"training_heatmap_features={}_num_topics={}.png\".format(\n",
    "        featurized_cell_table[\"featurization\"], num_topics))\n",
    "\n",
    "spatial_lda.visualization.plot_topics_heatmap(\n",
    "    trained_model.components_, featurized_cell_table[\"train_features\"].columns)\n",
    "plt.savefig(heatmap_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Visualize Topic Assignments\n",
    "Run the two code blocks below to visualize individual FOVs and the cell-level topic assignment.  The output will be saved to `viz_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Subset training cells\n",
    "fov_indices = featurized_cell_table[\"train_features\"].index.map(lambda x: x[0])\n",
    "cell_indices = featurized_cell_table[\"train_features\"].index.map(lambda x: x[1])\n",
    "training_cells = {}\n",
    "for i in np.unique(fov_indices):\n",
    "    training_cells[i] = cell_table[i].iloc[cell_indices[fov_indices == i],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose which FOVs to plot\n",
    "fov_set = list(training_cells.keys())[0:2]\n",
    "fov_labs = \"_\".join([str(x) for x in fov_set])\n",
    "\n",
    "_plot_fn = spu.make_plot_fn(\n",
    "    plot=\"topic_assignment\", topic_weights=trained_model.topic_weights, cell_table=training_cells)\n",
    "\n",
    "print(trained_model.topic_weights.columns)\n",
    "\n",
    "plot_path = os.path.join(\n",
    "    viz_dir,\n",
    "    \"training_topic_assignment_num_topics={}_fovs={}.png\".format(num_topics, fov_labs))\n",
    "\n",
    "# Generate Plot\n",
    "spatial_lda.visualization.plot_samples_in_a_row(\n",
    "    trained_model.topic_weights, _plot_fn, training_cells, fov_set)\n",
    "plt.savefig(plot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring Topic Weights on New Data\n",
    "Based on the output from the trained model, you can choose to infer topic weights on the entire pooled data by running the code below.  You can change the number of parallel processes if you like, otherwise it will be the same as when running the training algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "complete_model = spatial_lda.model.infer(\n",
    "    components=trained_model.components_,\n",
    "    sample_features=featurized_cell_table[\"featurized_fovs\"],\n",
    "    difference_matrices=difference_matrices[\"inference_diff_mat\"],\n",
    "    difference_penalty=difference_penalty,\n",
    "    max_dirichlet_iter=100,\n",
    "    max_dirichlet_ls_iter=100,\n",
    "    n_parallel_processes=num_processes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing and Saving Results\n",
    "\n",
    "You can use the same heatmap and plotting functions as above to visualize the results of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature-Topic Heatmap\n",
    "heatmap_path = os.path.join(\n",
    "    viz_dir, \"complete_heatmap_features={}_num_topics={}.png\".format(\n",
    "        featurized_cell_table[\"featurization\"], num_topics))\n",
    "\n",
    "spatial_lda.visualization.plot_topics_heatmap(\n",
    "    complete_model.components_, featurized_cell_table[\"featurized_fovs\"].columns)\n",
    "plt.savefig(heatmap_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell Topic Assignment\n",
    "fov_set = list(training_cells.keys())[0:2]\n",
    "fov_labs = \"_\".join([str(x) for x in fov_set])\n",
    "\n",
    "_plot_fn = spu.make_plot_fn(\n",
    "    plot=\"topic_assignment\", topic_weights=complete_model.topic_weights, cell_table=cell_table)\n",
    "\n",
    "plot_path = os.path.join(\n",
    "    viz_dir,\n",
    "    \"complete_topic_assignment_num_topics={}_fovs={}.png\".format(num_topics, fov_labs))\n",
    "\n",
    "# Generate Plot\n",
    "spatial_lda.visualization.plot_samples_in_a_row(\n",
    "    complete_model.topic_weights, _plot_fn, cell_table, fov_set)\n",
    "plt.savefig(plot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Saving the Trained and Complete Models\n",
    "Use the code below to save the trained and complete models for use on future data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trained Model\n",
    "train_name = \"trained_spatial_lda_model_num_topics={}_diff={}\".format(\n",
    "    num_topics, difference_penalty)\n",
    "\n",
    "spu.save_spatial_lda_file(\n",
    "    data=trained_model,\n",
    "    dir=os.path.join(base_dir, processed_dir),\n",
    "    file_name=train_name,\n",
    "    format=\"pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Complete Model\n",
    "complete_name = \"complete_spatial_lda_model_num_topics={}_diff={}\".format(\n",
    "    num_topics, difference_penalty)\n",
    "\n",
    "spu.save_spatial_lda_file(\n",
    "    data=complete_model,\n",
    "    dir=os.path.join(base_dir, processed_dir),\n",
    "    file_name=complete_name,\n",
    "    format=\"pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31e90e2a7155cbaa93471c58eaf30b3c41423e5d17fccea222aec5e482389189"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
