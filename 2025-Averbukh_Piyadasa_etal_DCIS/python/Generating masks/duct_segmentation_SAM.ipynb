{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970ee33-bc93-4025-8fea-3bf0001b2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior ro running, install SAM: https://github.com/facebookresearch/segment-anything\n",
    "# Download the SAM model from: https://github.com/facebookresearch/segment-anything#:~:text=First%20download%20a-,model%20checkpoint,-.%20Then%20the%20model\n",
    "\n",
    "# Set up \n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import sys\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde3e5a9-8a30-4c16-92e8-75f66f775ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeds\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a401c7-c3dd-429c-bb36-52aa62c4261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "    polygons = []\n",
    "    color = []\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        img = np.ones((m.shape[0], m.shape[1], 3))\n",
    "        color_mask = np.random.random((1, 3)).tolist()[0]\n",
    "        for i in range(3):\n",
    "            img[:,:,i] = color_mask[i]\n",
    "        ax.imshow(np.dstack((img, m*0.35)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493d2bce-84c0-4d8f-81d0-afeb5303fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the SAM model to be used for segmentation\n",
    "\n",
    "# # path to model file \n",
    "sam_checkpoint = \"/Users/innaa/Documents/seg anything models/sam_vit_h_4b8939.pth\"\n",
    "# model type\n",
    "model_type     = \"vit_h\"\n",
    "\n",
    "# path to model file \n",
    "# sam_checkpoint = \"/Users/innaa/Documents/seg anything models/sam_vit_b_01ec64.pth\"\n",
    "# # model type\n",
    "# model_type     = \"vit_b\"\n",
    "\n",
    "# # path to model file \n",
    "# sam_checkpoint = \"/Users/innaa/Documents/seg anything models/sam_vit_l_0b3195.pth\"\n",
    "# # model type\n",
    "# model_type     = \"vit_l\"\n",
    "\n",
    "#device = \"cuda\"\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "# SAM model custom params \n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_side=20,\n",
    "    pred_iou_thresh=0.88,\n",
    "    stability_score_thresh=0.95,\n",
    "    crop_n_layers=0,\n",
    "    crop_n_points_downscale_factor=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3358caad-a365-4c6e-b4c4-54380142e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make garyscale copposite from myoep+basal+liminal+tumor markers\n",
    "def create_composite_image(folder_path, fov,name_list):\n",
    "    images = []\n",
    "    \n",
    "    # Load channels and add them to composite\n",
    "    for name in name_list:\n",
    "        image_path = os.path.join(folder_path, name + \".tiff\")\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        # plt.imshow(image, cmap=\"gray\")\n",
    "        # plt.axis(\"off\")\n",
    "        # plt.show()\n",
    "        images.append(image)\n",
    "    if len(images) == 0:\n",
    "        return None\n",
    "    composite        = np.sum(images, axis=0)\n",
    "    composite        = (composite * 255).round().astype(np.uint8)\n",
    "    # Return composite\n",
    "    return composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78148a61-6175-4047-8430-4993b1081fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overlap(mask1, mask2):\n",
    "    # Make sure both masks have the same dimensions\n",
    "    assert mask1.shape == mask2.shape, \"Masks must have the same shape\"\n",
    "\n",
    "    # Calculate the number of pixels that are non-zero in both masks\n",
    "    overlap = np.logical_and(mask1, mask2).sum()\n",
    "\n",
    "    # Calculate the percentage of non-zero pixels in the first mask that have non-zero values in the second mask\n",
    "    percentage = overlap / np.count_nonzero(mask1) * 100\n",
    "\n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d27915-15e3-47fe-a035-96c3b4be29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define channels to be included in composite\n",
    "myoep         = ['ANXA1', 'Calponin1', 'SMA']\n",
    "tumor         = ['Ecadherin','EpCAM']\n",
    "luminal       = ['KRT15','KRT81','KRT18']\n",
    "basal         = [ 'KRT5', 'KRT14', 'KRT17']\n",
    "luminal_tumor = ['KRT7']\n",
    "name_list     = myoep + tumor + luminal + basal + luminal_tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c89d67b-5fc5-4972-8342-226763157e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fov list to loop over: DCIS and Normal breaast\n",
    "fov_list = ['TA535_R12C6','TA536_R1C1'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa62f50-df0e-4650-9d2e-2c3dc8604dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fov in fov_list:\n",
    "    # load and composite image\n",
    "    print(f'Masking {fov}')\n",
    "    folder_path = f'/Users/innaa/Documents/DCIS 2.0/20230417_image_test_set/{fov}/TIFs'  # Change based on folder structure\n",
    "    composite     = create_composite_image(folder_path, fov,name_list)\n",
    "\n",
    "    # Segment image \n",
    "    image_all = cv2.cvtColor(composite, cv2.COLOR_BGR2RGB)\n",
    "    masks2    = mask_generator.generate(image_all)\n",
    "\n",
    "    # Load the collagen image of the fov and binarize it \n",
    "    image_path       = os.path.join(folder_path, \"COL1A1.tiff\")\n",
    "    col_image        = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    col_image        = (col_image * 255).round().astype(np.uint8)\n",
    "    thresh_value     = 2\n",
    "    ret, bin_col     = cv2.threshold(col_image, thresh_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Binarize signal image \n",
    "    thresh_value     = 3\n",
    "    ret, bin_sig     = cv2.threshold(composite, thresh_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Define thresholds for mask exclusion\n",
    "    height, width  = bin_col.shape\n",
    "    size_max_tr    = 70*height*width\n",
    "    size_min_tr    = 1000\n",
    "    overlap_col_tr = 10\n",
    "    overlap_sig_tr = 2\n",
    "\n",
    "    # Mask post processing\n",
    "    new_masks2 = []  # create a new list to store the selected masks\n",
    "    for i, mask_dict in enumerate(masks2):\n",
    "        mask = mask_dict['segmentation'] \n",
    "        per_overlap_col = calculate_overlap(mask, bin_col)\n",
    "        per_overlap_sig = calculate_overlap(mask, bin_sig)\n",
    "        non_zero_pixels = mask_dict['area']\n",
    "        # check if the mask meets the size and overlap criteria\n",
    "        if (size_min_tr <= non_zero_pixels <= size_max_tr) and  (overlap_sig_tr <= per_overlap_sig) and  ((per_overlap_col <= overlap_col_tr and overlap_sig_tr <= per_overlap_sig) or (per_overlap_col >= overlap_col_tr and per_overlap_col <= per_overlap_sig)):\n",
    "            new_masks2.append(mask_dict) \n",
    "\n",
    "    # Combine the masks into a single binary mask\n",
    "    sum_mask = np.zeros_like(composite, dtype=np.uint8)\n",
    "    # Iterate over each mask and add it to the sum of the masks\n",
    "    for mask_dict in new_masks2:\n",
    "        mask = mask_dict['segmentation']\n",
    "        mask = mask.astype(np.uint8)\n",
    "        sum_mask = cv2.add(sum_mask, mask)\n",
    "    # Convert the sum of the masks to a binary mask\n",
    "    sum_mask = cv2.threshold(sum_mask, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # Save segmentation mask\n",
    "    epi_mask_filename = f'{folder_path}/epi_mask.tiff'\n",
    "    cv2.imwrite(epi_mask_filename, sum_mask)\n",
    "\n",
    "    # Save the composite image\n",
    "    composite_filename = f'{folder_path}/composite_image.tiff'  \n",
    "    cv2.imwrite(composite_filename, composite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
