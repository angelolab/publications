{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e012798-3632-4107-8d5a-5f47e7671a9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## This notebook is an example: create a copy before running it or you will get merge conflicts!\n",
    "\n",
    "This notebook will walk you through the process of normalizing your image data. Before running through the notebook, make sure you've completed section 3 of `1_set_up_toffy.ipynb`, and that your data has already been compensated with rosetta using `4_compensate_image_data.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9751084-7855-4005-b152-55895ff40823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import skimage.io as io # new\n",
    "\n",
    "from toffy import normalize\n",
    "from ark.utils.io_utils import list_files, list_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe49e0b-34c2-4f86-b786-403c24b2f678",
   "metadata": {},
   "source": [
    "### You'll first need to specify the location of the relevant files to enable image normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f48127b8-84da-4763-9c44-01a5bde4c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First specify the name of the run that you'll be normalizing\n",
    "\n",
    "# Then provide the path to your panel\n",
    "panel_path = 'I:\\\\20220518_TONIC_panel_file.csv'\n",
    "panel = pd.read_csv(panel_path)\n",
    "\n",
    "# These paths should point to the folders containing each step of the processing pipeline\n",
    "bin_base_dir = 'I:\\\\run_files'\n",
    "rosetta_base_dir = 'I:\\\\rosetta'\n",
    "normalized_base_dir = 'I:\\\\normalized'\n",
    "mph_base_dir = bin_base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e94eb1c-4c55-4c37-99bf-36b9402337a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "moly_base_dir = 'I:\\\\moly_run_fovs'\n",
    "runs = list_folders(rosetta_base_dir)\n",
    "for run in runs[2:]:\n",
    "    run_dir = os.path.join(bin_base_dir, run)\n",
    "    new_dir = os.path.join(moly_base_dir, run)\n",
    "    os.makedirs(new_dir)\n",
    "    moly_fovs = json_utils.list_moly_fovs(run_dir)\n",
    "    for fov in moly_fovs:\n",
    "        files = list_files(run_dir, fov)\n",
    "        for file in files:\n",
    "            shutil.move(os.path.join(run_dir, file), \n",
    "                            os.path.join(new_dir, file))\n",
    "        \n",
    "        shutil.rmtree(os.path.join(rosetta_base_dir, run, fov))\n",
    "        shutil.rmtree(os.path.join('I:\\\\extracted', run, fov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fc7a0e6-141b-4032-887f-ebbed0a4f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_name in run_names[3:]:\n",
    "    run_dir = os.path.join(bin_base_dir, run_name)\n",
    "    previous_pulses = list_files(run_dir, 'pulse')\n",
    "    for file in previous_pulses:\n",
    "        os.remove(os.path.join(run_dir, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59c4a6bc-a2ce-4d68-b499-bfd244d6a7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2022-02-21_TONIC_TMA11_run2',\n",
       " '2022-02-23_TONIC_TMA12_run1',\n",
       " '2022-02-24_TONIC_TMA12_run2',\n",
       " '2022-02-25_TONIC_TMA12_run3',\n",
       " '2022-02-26_TONIC_TMA13',\n",
       " '2022-02-26_TONIC_TMA13_restart',\n",
       " '2022-02-28_TONIC_TMA13_run2',\n",
       " '2022-03-01_TONIC_TMA14_run1',\n",
       " '2022-03-02_TONIC_TMA14_run2',\n",
       " '2022-03-03_TONIC_TMA15_run1',\n",
       " '2022-03-04_TONIC_TMA15_run2',\n",
       " '2022-03-05_TONIC_TMA15_run3']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_names = list_folders(rosetta_base_dir)\n",
    "run_names[18:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62142cdc-fb78-4c21-8cb2-77b3fb60d399",
   "metadata": {},
   "source": [
    "### Then, we'll loop over each FOV, generating the necessary normalization files if they weren't already created, then normalizing the images, and finally saving them to the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe67691-1676-4c3a-93fc-491e3abd6a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_names = list_folders(rosetta_base_dir)\n",
    "#for run_name in run_names[18:30]:\n",
    "for run_name in ['2022-03-01_TONIC_TMA14_run1a', '2022-03-01_TONIC_TMA14_run1b']:\n",
    "    print(\"analyzing run {}\".format(run_name))\n",
    "    # specify sub-folder for rosetta images\n",
    "    img_sub_folder = 'normalized'\n",
    "\n",
    "    # create directory to hold normalized images\n",
    "    normalized_run_dir = os.path.join(normalized_base_dir, run_name)\n",
    "    if not os.path.exists(normalized_run_dir):\n",
    "        os.makedirs(normalized_run_dir)\n",
    "\n",
    "    # create directory to hold associated processing files\n",
    "    mph_run_dir = os.path.join(mph_base_dir, run_name)\n",
    "    if not os.path.exists(mph_run_dir):\n",
    "        os.makedirs(mph_run_dir)\n",
    "\n",
    "    # get all FOVs\n",
    "    fovs = list_folders(os.path.join(rosetta_base_dir, run_name), 'fov')\n",
    "\n",
    "    # loop over each FOV\n",
    "    for fov in fovs:\n",
    "        # generate mph values\n",
    "        mph_file_path = os.path.join(mph_run_dir, fov + '_pulse_heights.csv')\n",
    "        if not os.path.exists(mph_file_path):\n",
    "            normalize.write_mph_per_mass(base_dir=os.path.join(bin_base_dir, run_name), output_dir=mph_run_dir, \n",
    "                                         fov=fov, masses=panel['Mass'].values, start_offset=0.3, stop_offset=0)\n",
    "        \n",
    "    normalize.normalize_image_data(img_dir=os.path.join(rosetta_base_dir, run_name), norm_dir=normalized_run_dir, pulse_height_dir=mph_run_dir,\n",
    "                               panel_info=panel, img_sub_folder=img_sub_folder, mass_obj_func='poly_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0096ea-491a-45c3-adb8-6db7ffc06a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = '2022-03-01_TONIC_TMA14_run1b'\n",
    "normalize.create_fitted_pulse_heights_file(pulse_height_dir=os.path.join(bin_base_dir, run_name), panel_info=panel, \n",
    "                                           norm_dir=os.path.join(normalized_base_dir, run_name), mass_obj_func='poly_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "893e7f82-96e9-471b-b1ac-4e36e6e272b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stitched image of before and after\n",
    "import skimage.io as io\n",
    "import natsort as ns\n",
    "from ark.utils import data_utils, load_utils, io_utils\n",
    "import numpy as np\n",
    "\n",
    "normalized=True\n",
    "unnormalized=False\n",
    "\n",
    "# problematic runs to check\n",
    "\n",
    "# bad curve fit: 2022-03-01_TONIC_TMA14_run1\n",
    "run_name = '2022-01-14_TONIC_TMA2_run1'\n",
    "#run_name = '2022-03-13_TONIC_TMA18_run1'\n",
    "\n",
    "normalized_run_dir = os.path.join(normalized_base_dir, run_name)\n",
    "unnormalized_run_dir = os.path.join(rosetta_base_dir, run_name)\n",
    "\n",
    "folders = io_utils.list_folders(normalized_run_dir, 'fov-')\n",
    "folders = ns.natsorted(folders)\n",
    "\n",
    "if normalized:\n",
    "    # get all channels\n",
    "    channels = load_utils.load_imgs_from_tree(unnormalized_run_dir,\n",
    "                                                fovs=folders[:1],\n",
    "                                                img_sub_folder='normalized', \n",
    "                                               dtype='float32').channels.values\n",
    "\n",
    "    # load and stitch normalized data\n",
    "    stitch_dir = os.path.join(normalized_run_dir, 'stitched_images_normalized')\n",
    "    if not os.path.exists(stitch_dir):\n",
    "        os.makedirs(stitch_dir)\n",
    "\n",
    "    for chan in channels[1:]:\n",
    "        img_data = load_utils.load_imgs_from_tree(normalized_run_dir,\n",
    "                                                fovs=folders,\n",
    "                                                img_sub_folder='', \n",
    "                                               dtype='float32',\n",
    "                                                 channels=[chan], \n",
    "                                                 max_image_size=2048)\n",
    "\n",
    "        stitched = data_utils.stitch_images(img_data, int(np.floor(np.sqrt(img_data.shape[0]))))\n",
    "\n",
    "\n",
    "        # save normalized data\n",
    "        current_img = stitched.loc['stitched_image', :, :, chan].values\n",
    "        io.imsave(os.path.join(stitch_dir, chan + '.tiff'), current_img.astype('float32'), check_contrast=False)\n",
    "\n",
    "\n",
    "if unnormalized:\n",
    "\n",
    "    # load and stitch unnormalized data\n",
    "    unnormalized_run_dir = os.path.join(rosetta_base_dir, run_name)\n",
    "\n",
    "    stitch_dir = os.path.join(normalized_run_dir, 'stitched_images_unnormalized')\n",
    "    if not os.path.exists(stitch_dir):\n",
    "        os.makedirs(stitch_dir)\n",
    "\n",
    "    for chan in channels:\n",
    "        img_data = load_utils.load_imgs_from_tree(unnormalized_run_dir,\n",
    "                                                fovs=folders,\n",
    "                                                img_sub_folder='normalized', \n",
    "                                               dtype='float32',\n",
    "                                                 channels=[chan],\n",
    "                                                 max_image_size=2048)\n",
    "\n",
    "        stitched = data_utils.stitch_images(img_data, int(np.floor(np.sqrt(img_data.shape[0]))))\n",
    "\n",
    "\n",
    "        # save normalized data\n",
    "        current_img = stitched.loc['stitched_image', :, :, chan].values\n",
    "        io.imsave(os.path.join(stitch_dir, chan + '.tiff'), current_img.astype('float32'), check_contrast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0cfdeff-617f-4595-a596-4883513257b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CD11c'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = io.imread(os.path.join(normalized_run_dir, 'fov-1-scan-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719e550b-824e-4517-912c-2c70dc24a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = load_utils.load_imgs_from_tree(normalized_run_dir,\n",
    "                                                    fovs=folders[38:39],\n",
    "                                                    img_sub_folder='', \n",
    "                                                   dtype='float32',\n",
    "                                                     channels=[chan], \n",
    "                                                     max_image_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "08694a70-2aa3-4d5b-9616-e604342ae57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulse_heights = pd.read_csv(os.path.join(mph_base_dir, run_name + '_small_window', 'pulse_heights_combined.csv'))\n",
    "masses = np.unique(panel['Mass'])\n",
    "for i in range(1, 10):\n",
    "        old_name = 'fov-{}-scan-1'.format(i)\n",
    "        new_name = 'fov-0{}-scan-1'.format(i)\n",
    "        pulse_heights = pulse_heights.replace(old_name, new_name)\n",
    "\n",
    "for mass in masses[:1]:\n",
    "    mass = 175\n",
    "    pulse_heights = pulse_heights.sort_values('fov')\n",
    "    fovs = np.unique(pulse_heights['fov'])\n",
    "    mo_fovs = [fov.split('-scan')[0] for fov in fovs if 'scan-2' in fov]\n",
    "    complete_mo_fovs = []\n",
    "    for fov in mo_fovs:\n",
    "        complete_mo_fovs.append(fov + '-scan-1')\n",
    "        complete_mo_fovs.append(fov + '-scan-2')\n",
    "        complete_mo_fovs.append(fov + '-scan-3')\n",
    "    fovs = [fov for fov in fovs if fov not in complete_mo_fovs]\n",
    "    pulse_heights = pulse_heights.loc[np.isin(pulse_heights['fov'], fovs), :]\n",
    "\n",
    "    y = pulse_heights.loc[pulse_heights['mass'] == mass, 'pulse_height'].values\n",
    "    x = np.linspace(0, len(y) - 1, len(y))\n",
    "\n",
    "\n",
    "    def reg_func(_x, _y):\n",
    "        return np.polyval(np.polyfit(_x, _y, 2), np.linspace(0, len(x), len(x)))\n",
    "\n",
    "\n",
    "    from seaborn import algorithms as algo\n",
    "    from seaborn.utils import ci\n",
    "    yhat_boots = algo.bootstrap(pd.Series(x), pd.Series(y), func=reg_func,\n",
    "                                n_boot=1000, units=None)\n",
    "    err_bands = ci(yhat_boots, 95, axis=0)\n",
    "\n",
    "    top_band = err_bands[1]\n",
    "    outlier_fovs = []\n",
    "    for idx, val in enumerate(y):\n",
    "        if val > top_band[idx]:\n",
    "            outlier_fovs.append(fovs[idx])\n",
    "\n",
    "    outlier_fovs = [fov.replace('-0', '-') for fov in outlier_fovs]\n",
    "    \n",
    "    # create directory to hold stiched images\n",
    "    out_dir = os.path.join(normalized_base_dir, run_name, 'outlier_fovs_{}'.format(mass))\n",
    "    os.makedirs(out_dir)\n",
    "    channel_name = panel.loc[panel['Mass'] == mass, 'Target'].values[0]\n",
    "    \n",
    "    img_data = load_utils.load_imgs_from_tree(os.path.join(rosetta_base_dir, run_name),\n",
    "                                            img_sub_folder='normalized', \n",
    "                                            dtype='float32',\n",
    "                                              fovs=outlier_fovs,\n",
    "                                             channels=[channel_name],\n",
    "                                             max_image_size=2048)\n",
    "\n",
    "    stitched = data_utils.stitch_images(img_data, int(np.floor(np.sqrt(img_data.shape[0]))))\n",
    "\n",
    "\n",
    "    # save normalized data\n",
    "    current_img = stitched.loc['stitched_image', :, :, channel_name].values\n",
    "    io.imsave(os.path.join(out_dir, channel_name + '.tiff'), current_img, check_contrast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "14082e50-978c-424f-88ca-f43e9a2251e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fov-3-scan-1',\n",
       " 'fov-12-scan-1',\n",
       " 'fov-13-scan-1',\n",
       " 'fov-16-scan-1',\n",
       " 'fov-18-scan-1',\n",
       " 'fov-22-scan-1',\n",
       " 'fov-30-scan-1',\n",
       " 'fov-34-scan-1',\n",
       " 'fov-38-scan-1',\n",
       " 'fov-45-scan-1',\n",
       " 'fov-51-scan-1',\n",
       " 'fov-54-scan-1',\n",
       " 'fov-55-scan-1']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_fovs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "157f10ae-e8b3-42b9-a4d1-af83584fb9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fov-50-scan-1',\n",
       " 'fov-51-scan-1',\n",
       " 'fov-52-scan-1',\n",
       " 'fov-54-scan-1',\n",
       " 'fov-55-scan-1']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fovs[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45d9b021-c96a-4979-a1dd-73371a35e2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plots\n",
    "import os\n",
    "import pandas as pd\n",
    "from ark.utils import io_utils\n",
    "\n",
    "run_names = ['2022-01-14_TONIC_TMA2_run1', '2022-01-21_TONIC_TMA5', '2022-01-26_TONIC_TMA9', '2022-02-26_TONIC_TMA13',\n",
    "            '2022-03-02_TONIC_TMA14_run2', '2022-03-14_TONIC_TMA18_run3', '2022-04-05_TONIC_TMA20_run1', '2022-04-10_TONIC_TMA22_run1']\n",
    "\n",
    "for run in run_names:\n",
    "    run_dir = os.path.join(mph_base_dir, run + '_small_window')\n",
    "    files = io_utils.list_files(run_dir, '_pulse_heights')\n",
    "\n",
    "    metrics = []\n",
    "    for file in files:\n",
    "        metrics.append(pd.read_csv(os.path.join(run_dir, file)))\n",
    "\n",
    "    metrics = pd.concat(metrics)\n",
    "\n",
    "    metrics.to_csv(os.path.join(run_dir, 'pulse_heights_combined.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38865fa9-22ad-40b8-a783-9005420f90b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import natsort as ns\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for run in run_names[:1]:\n",
    "    run_dir = os.path.join(mph_base_dir, run + '_small_window')\n",
    "    pulse_heights = pd.read_csv(os.path.join(run_dir, 'pulse_heights_combined.csv'))\n",
    "    fovs = ns.natsorted(pulse_heights['fov'].unique())\n",
    "    \n",
    "    mo_fovs = [fov.split('-scan')[0] for fov in fovs if 'scan-2' in fov]\n",
    "    complete_mo_fovs = []\n",
    "    for fov in mo_fovs:\n",
    "        complete_mo_fovs.append(fov + '-scan-1')\n",
    "        complete_mo_fovs.append(fov + '-scan-2')\n",
    "        complete_mo_fovs.append(fov + '-scan-3')\n",
    "    fovs = [fov for fov in fovs if fov not in complete_mo_fovs]\n",
    "    pulse_heights = pulse_heights.loc[np.isin(pulse_heights['fov'], fovs), :]\n",
    "    \n",
    "    pulse_heights['fov'] = pd.Categorical(pulse_heights['fov'], ordered=True,\n",
    "                                               categories=ns.natsorted(pulse_heights['fov'].unique()))\n",
    "    pulse_heights = pulse_heights.sort_values('fov')\n",
    "\n",
    "    # add numerical column for fovs to enable easier plotting by acq order\n",
    "    fov_names = pulse_heights['fov'].values.tolist()\n",
    "    fov_nums = [float(fov_name.split('-')[1]) for fov_name in fov_names]\n",
    "    pulse_heights['acq_order'] = fov_nums\n",
    "\n",
    "    for mass in np.unique(pulse_heights['mass'].values):\n",
    "\n",
    "        plot_data = pulse_heights.loc[pulse_heights['mass'] == mass]\n",
    "\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        # g = sns.FacetGrid(data=plot_data, x='acq_order', y='pulse_height')\n",
    "        sns.regplot(x='acq_order', y='pulse_height', data=plot_data, order=2)\n",
    "\n",
    "        plot_dir = os.path.join(run_dir, 'mph_v_acq_per_mass')\n",
    "        if not os.path.exists(plot_dir):\n",
    "            os.makedirs(plot_dir)\n",
    "        plt.savefig(os.path.join(plot_dir, str(mass) + '_mph_vs_acq.pdf'), bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43dbe77-86fa-44df-acb6-ec0c6f1b6415",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_path = os.path.join(bin_base_dir, run_name, 'fov-18-scan-1.json')\n",
    "with open(json_path, 'r') as jp:\n",
    "    json_file = json.load(jp)\n",
    "\n",
    "json_file['standardTarget']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
